{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"application/vnd.jupyter.widget-state+json":{"77526812ddf044d197cb0edc9fd63a3a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c782d2fe68a34cdcb9dee1faf7bbe28a","IPY_MODEL_cbd0517b54a24958bd598303e14c26a0","IPY_MODEL_25e98a708c224625a1f3cb0bfbf89846"],"layout":"IPY_MODEL_e17e7e1c7b40476d9d399f1cde9a66db"}},"c782d2fe68a34cdcb9dee1faf7bbe28a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c360584b8a0447aab3cfd3d8d68ec13c","placeholder":"​","style":"IPY_MODEL_e70e2d40bb144cd49ad402c0de78ab28","value":"model.safetensors: 100%"}},"cbd0517b54a24958bd598303e14c26a0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_827f5ad5bc9b4e3c9e80504c22a34289","max":5702746383,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5cac9c43751947b0a4cd170b25612af7","value":5702745840}},"25e98a708c224625a1f3cb0bfbf89846":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1acfe7f5763d48589fc91e3340fb6633","placeholder":"​","style":"IPY_MODEL_7e69eda079d34d5a8237b9891c54dde4","value":" 5.70G/5.70G [00:30&lt;00:00, 402MB/s]"}},"e17e7e1c7b40476d9d399f1cde9a66db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c360584b8a0447aab3cfd3d8d68ec13c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e70e2d40bb144cd49ad402c0de78ab28":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"827f5ad5bc9b4e3c9e80504c22a34289":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cac9c43751947b0a4cd170b25612af7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1acfe7f5763d48589fc91e3340fb6633":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e69eda079d34d5a8237b9891c54dde4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e420322e6cfa49be899e60d09ac79b34":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_68b9147bcdc9464bbce3be306f8cd71c","IPY_MODEL_a4fd216bd9174221a05e5e5fca9dcc02","IPY_MODEL_1d6e29dea712405e91a65f5d509d72c0"],"layout":"IPY_MODEL_3ce01164e44b4c1c83cf96797afacd63"}},"68b9147bcdc9464bbce3be306f8cd71c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a4146355038498188a661e06b9e640b","placeholder":"​","style":"IPY_MODEL_42bc292dd9314507a0d630e882b2d9a8","value":"generation_config.json: 100%"}},"a4fd216bd9174221a05e5e5fca9dcc02":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_028ce3f8d4d84659b102a011fcfecb55","max":234,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5dbe42dd1dc6463bb608195024f5f334","value":234}},"1d6e29dea712405e91a65f5d509d72c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9cf3f0eca84241b296bc63cc95adb853","placeholder":"​","style":"IPY_MODEL_25bc8360bfdb45b8adfe48af80c054b7","value":" 234/234 [00:00&lt;00:00, 10.9kB/s]"}},"3ce01164e44b4c1c83cf96797afacd63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a4146355038498188a661e06b9e640b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42bc292dd9314507a0d630e882b2d9a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"028ce3f8d4d84659b102a011fcfecb55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5dbe42dd1dc6463bb608195024f5f334":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9cf3f0eca84241b296bc63cc95adb853":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25bc8360bfdb45b8adfe48af80c054b7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f9a04a91b96e462dac19311d9714de87":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a4274391df874147877a211109183853","IPY_MODEL_8d13dd8a82c44e01bde4743b12a80252","IPY_MODEL_42b62a340891454c9a7b95324530000c"],"layout":"IPY_MODEL_284b481cd3cf4b65b52f0a6cd09905d1"}},"a4274391df874147877a211109183853":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_94f343cb1bc945cea1d5d0e96a279ea7","placeholder":"​","style":"IPY_MODEL_44cbf1256cf947dcaff5ba55d5a8c9f7","value":"tokenizer_config.json: 100%"}},"8d13dd8a82c44e01bde4743b12a80252":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8140f40d66dc4a5fb860a715abb0c79e","max":55421,"min":0,"orientation":"horizontal","style":"IPY_MODEL_70e26ca3e63243d2b1619b26a87f3436","value":55421}},"42b62a340891454c9a7b95324530000c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5cbad8828d74ff0886effb5d5cd60b4","placeholder":"​","style":"IPY_MODEL_02c7c8b7a1d140efb1cbe287f35c6da5","value":" 55.4k/55.4k [00:00&lt;00:00, 3.03MB/s]"}},"284b481cd3cf4b65b52f0a6cd09905d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94f343cb1bc945cea1d5d0e96a279ea7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44cbf1256cf947dcaff5ba55d5a8c9f7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8140f40d66dc4a5fb860a715abb0c79e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70e26ca3e63243d2b1619b26a87f3436":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f5cbad8828d74ff0886effb5d5cd60b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02c7c8b7a1d140efb1cbe287f35c6da5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dce557af52704211b102937aea9b22d9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b771513fd36b4ce59b1d7b2cd5d16d4b","IPY_MODEL_d6993d2f38ec492b8b605ec4a9da7462","IPY_MODEL_f2ff20f18b6d480ebd5836b81afb18f5"],"layout":"IPY_MODEL_5e061ff7baf942879af6e8e87caa0f0a"}},"b771513fd36b4ce59b1d7b2cd5d16d4b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffdc2927262f4a63a89b13ec92a5e8cb","placeholder":"​","style":"IPY_MODEL_1d1cc1b087e54b51b824cae9b5dda375","value":"tokenizer.json: 100%"}},"d6993d2f38ec492b8b605ec4a9da7462":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f470eea92b0144b08b43de64b2b92eab","max":9085657,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c331c89b2b03424681c99b648861fef1","value":9085657}},"f2ff20f18b6d480ebd5836b81afb18f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f2a9bb834984efd822c49bd8a976bc5","placeholder":"​","style":"IPY_MODEL_f434e0ea14c646bd8e6032e963b5ebfa","value":" 9.09M/9.09M [00:00&lt;00:00, 19.1MB/s]"}},"5e061ff7baf942879af6e8e87caa0f0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffdc2927262f4a63a89b13ec92a5e8cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d1cc1b087e54b51b824cae9b5dda375":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f470eea92b0144b08b43de64b2b92eab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c331c89b2b03424681c99b648861fef1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6f2a9bb834984efd822c49bd8a976bc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f434e0ea14c646bd8e6032e963b5ebfa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f932a4502a254b8d88c52bcd85564045":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e05023f3f9bd4caf8683c0791151b1d8","IPY_MODEL_100b69e7e968428fbd6a6048928840d8","IPY_MODEL_fca0088e1a6b4fc08aea6d9c041365dd"],"layout":"IPY_MODEL_7a644778e46f42e5b6f77ad2352ef55b"}},"e05023f3f9bd4caf8683c0791151b1d8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfa9ed2ce8df4b519b81a8055ec35b96","placeholder":"​","style":"IPY_MODEL_50007b0f16bf48c08474a16a2f516015","value":"special_tokens_map.json: 100%"}},"100b69e7e968428fbd6a6048928840d8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_35c0a79f2e7942539ca12d2f8830ad28","max":340,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c35a06950d9f4305a43bc8dbaf7e095d","value":340}},"fca0088e1a6b4fc08aea6d9c041365dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4243bb9d55044d9b6d98b28af98b8a5","placeholder":"​","style":"IPY_MODEL_19d07031c6404ef597b526f7a736fb4a","value":" 340/340 [00:00&lt;00:00, 26.3kB/s]"}},"7a644778e46f42e5b6f77ad2352ef55b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfa9ed2ce8df4b519b81a8055ec35b96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50007b0f16bf48c08474a16a2f516015":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"35c0a79f2e7942539ca12d2f8830ad28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c35a06950d9f4305a43bc8dbaf7e095d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f4243bb9d55044d9b6d98b28af98b8a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19d07031c6404ef597b526f7a736fb4a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dfbebab4648f4587a2b69c2b967c8d53":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bc16617c16dd43eaad83b866e0650181","IPY_MODEL_a0940ce1cfdf49f1a2218bdbe0881a66","IPY_MODEL_c5f80e90b30441e3b3e6fe6c27a3b448"],"layout":"IPY_MODEL_f545d721c72547f2a2eacc8a5274f88a"}},"bc16617c16dd43eaad83b866e0650181":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6c2d4eec6214735bffdcbaca19d16d3","placeholder":"​","style":"IPY_MODEL_2880c91657f54d2b95e538144725a590","value":"Map: 100%"}},"a0940ce1cfdf49f1a2218bdbe0881a66":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9159af7acc2451c85d7dc86f6395cd9","max":5749,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ef20cb6c51664c3d8d6a5aab7382e2e0","value":5749}},"c5f80e90b30441e3b3e6fe6c27a3b448":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_74acd0bf7b9541d79beeffa9abe838f0","placeholder":"​","style":"IPY_MODEL_04e015954efe4efd9247fdf5a0cd1187","value":" 5749/5749 [00:00&lt;00:00, 57130.46 examples/s]"}},"f545d721c72547f2a2eacc8a5274f88a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6c2d4eec6214735bffdcbaca19d16d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2880c91657f54d2b95e538144725a590":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a9159af7acc2451c85d7dc86f6395cd9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef20cb6c51664c3d8d6a5aab7382e2e0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"74acd0bf7b9541d79beeffa9abe838f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04e015954efe4efd9247fdf5a0cd1187":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cbbd1295d909478fa1560ae5c6780373":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7c67acc6723d4eeebb89591c78b8d742","IPY_MODEL_92f1f01de9ea4963a4a8f8bb56335a14","IPY_MODEL_71d1ec57a60e4f159dde8fe5423625ed"],"layout":"IPY_MODEL_239990396a4b4588827e35a605076db9"}},"7c67acc6723d4eeebb89591c78b8d742":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab4f47a0adad424996ccf8b7c8660a5d","placeholder":"​","style":"IPY_MODEL_c5e696ab8e5145ce8919a69ce0a85cd3","value":"Map (num_proc=2): 100%"}},"92f1f01de9ea4963a4a8f8bb56335a14":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c626e6cacb74a098f1d173bb159bd78","max":5749,"min":0,"orientation":"horizontal","style":"IPY_MODEL_050a4ce725a446189834b42410b67811","value":5749}},"71d1ec57a60e4f159dde8fe5423625ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a55640dd1b646d6892dc2f442366be7","placeholder":"​","style":"IPY_MODEL_f8db0f897e2e45d18093f10f14d0527d","value":" 5749/5749 [00:03&lt;00:00, 2672.44 examples/s]"}},"239990396a4b4588827e35a605076db9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab4f47a0adad424996ccf8b7c8660a5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5e696ab8e5145ce8919a69ce0a85cd3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c626e6cacb74a098f1d173bb159bd78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"050a4ce725a446189834b42410b67811":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5a55640dd1b646d6892dc2f442366be7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8db0f897e2e45d18093f10f14d0527d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"56db586213ff41b8ad24b0dccf45d784":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6c16b750eb6446c786ca161824242b25","IPY_MODEL_c848086dbd304393bef04cb35bbe71a1","IPY_MODEL_2e6c1e4873fd411a843f7d9be9f23554"],"layout":"IPY_MODEL_f96511ae28354340bc985fec6f4c1352"}},"6c16b750eb6446c786ca161824242b25":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_937e369bd97c463487d25b3a795a987f","placeholder":"​","style":"IPY_MODEL_a2610909c0294073a21aee3c7f578381","value":"README.md: 100%"}},"c848086dbd304393bef04cb35bbe71a1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b227a8babca4ba09c8d37ebaa8d31da","max":609,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6ecfc25bebd845909b481cf404f556c7","value":609}},"2e6c1e4873fd411a843f7d9be9f23554":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45afc85954454ec191ac5e7ac0561b16","placeholder":"​","style":"IPY_MODEL_166797f31534422a9ba04481d6656561","value":" 609/609 [00:00&lt;00:00, 22.8kB/s]"}},"f96511ae28354340bc985fec6f4c1352":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"937e369bd97c463487d25b3a795a987f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2610909c0294073a21aee3c7f578381":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0b227a8babca4ba09c8d37ebaa8d31da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ecfc25bebd845909b481cf404f556c7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"45afc85954454ec191ac5e7ac0561b16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"166797f31534422a9ba04481d6656561":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0bdde16038674f1585b00d92785893d0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f6e2e25496724ddda2f1d09188480f20","IPY_MODEL_75d5b9da3a8c4fa9a92f150a7110f77a","IPY_MODEL_fcb98ce31da24386b93d3aebbde82b32"],"layout":"IPY_MODEL_920d2dd713514b12b9c139e3520f2a6c"}},"f6e2e25496724ddda2f1d09188480f20":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_516baa04d6c649178fabc54915cc7dd2","placeholder":"​","style":"IPY_MODEL_5337ecad36d14ec59ebaf637b4e63759","value":"100%"}},"75d5b9da3a8c4fa9a92f150a7110f77a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7edc4e0a623b4264b89e04d4f8175f0d","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a82c4c30a05f4ba6894466fcb70e0815","value":1}},"fcb98ce31da24386b93d3aebbde82b32":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2da198438294b7e82f2bf8fe37faa31","placeholder":"​","style":"IPY_MODEL_ad23989074434310b42411ec657591b6","value":" 1/1 [00:02&lt;00:00,  2.05s/it]"}},"920d2dd713514b12b9c139e3520f2a6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"516baa04d6c649178fabc54915cc7dd2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5337ecad36d14ec59ebaf637b4e63759":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7edc4e0a623b4264b89e04d4f8175f0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a82c4c30a05f4ba6894466fcb70e0815":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e2da198438294b7e82f2bf8fe37faa31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad23989074434310b42411ec657591b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e03ed95c09d64d27b044695dd28bb39a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d2bed13ef1bf48d7be1adda75872ba60","IPY_MODEL_e96b6eabfe4c4c778d60bf6128e3f32d","IPY_MODEL_69584268c9ab4780865d451e26a7794a"],"layout":"IPY_MODEL_e6d0b86bc4974ff9a27b4890dc026ddb"}},"d2bed13ef1bf48d7be1adda75872ba60":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_669eac91787e4a32885d4d87239e8929","placeholder":"​","style":"IPY_MODEL_499bf4b92f44410ebe52a117467dd10c","value":"adapter_model.safetensors: "}},"e96b6eabfe4c4c778d60bf6128e3f32d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_04da4cead6114d53a923fc6bc13f5698","max":167832240,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ac97efe66be9461b826cd7479361c349","value":167832240}},"69584268c9ab4780865d451e26a7794a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75c188864be749e6875bc4aad51c2f69","placeholder":"​","style":"IPY_MODEL_183582df6dae4b3e8fa0749f87ff1f7a","value":" 176M/? [00:01&lt;00:00, 136MB/s]"}},"e6d0b86bc4974ff9a27b4890dc026ddb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"669eac91787e4a32885d4d87239e8929":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"499bf4b92f44410ebe52a117467dd10c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"04da4cead6114d53a923fc6bc13f5698":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac97efe66be9461b826cd7479361c349":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"75c188864be749e6875bc4aad51c2f69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"183582df6dae4b3e8fa0749f87ff1f7a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n<div class=\"align-center\">\n  <a href=\"https://github.com/unslothai/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n  <a href=\"https://discord.gg/u54VK8m8tk\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n  <a href=\"https://ko-fi.com/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Kofi button.png\" width=\"145\"></a></a> Join Discord if you need help + ⭐ <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ⭐\n</div>\n\nTo install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://github.com/unslothai/unsloth?tab=readme-ov-file#-installation-instructions).\n\nYou will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save) (eg for Llama.cpp).\n\n[NEW] Llama-3.1 8b, 70b & 405b are trained on a crazy 15 trillion tokens with 128K long context lengths!\n\n**[NEW] Try 2x faster inference in a free Colab for Llama-3.1 8b Instruct [here](https://colab.research.google.com/drive/1T-YBVfnphoVc8E2E854qF3jdia2Ll2W2?usp=sharing)**","metadata":{"id":"IqM-T1RTzY6C"}},{"cell_type":"code","source":"# Installs Unsloth, Xformers (Flash Attention) and all other packages!\n!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n\n# We have to check which Torch version for Xformers (2.3 -> 0.0.27)\nfrom torch import __version__; from packaging.version import Version as V\nxformers = \"xformers==0.0.27\" if V(__version__) < V(\"2.4.0\") else \"xformers\"\n!pip install --no-deps {xformers} trl peft accelerate bitsandbytes triton","metadata":{"id":"2eSvM9zX_2d3","execution":{"iopub.status.busy":"2024-11-02T08:08:52.974828Z","iopub.execute_input":"2024-11-02T08:08:52.975156Z","iopub.status.idle":"2024-11-02T08:10:02.791781Z","shell.execute_reply.started":"2024-11-02T08:08:52.975120Z","shell.execute_reply":"2024-11-02T08:10:02.790525Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-86jnuovm/unsloth_dafcff2607694f5e95452d0d7277d512\n  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-86jnuovm/unsloth_dafcff2607694f5e95452d0d7277d512\n  Resolved https://github.com/unslothai/unsloth.git to commit a2f8db3e7341f983af5814a2c56f54fa29ee548d\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting unsloth-zoo (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading unsloth_zoo-2024.11.0-py3-none-any.whl.metadata (27 kB)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (21.3)\nCollecting tyro (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading tyro-0.8.14-py3-none-any.whl.metadata (8.4 kB)\nCollecting transformers>=4.44.2 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading transformers-4.46.1-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets>=2.16.0 in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.21.0)\nRequirement already satisfied: sentencepiece>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.3)\nRequirement already satisfied: wheel>=0.42.0 in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.43.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.26.4)\nRequirement already satisfied: protobuf<4.0.0 in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.24.6)\nCollecting hf-transfer (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\nCollecting bitsandbytes>=0.43.3 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.44.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.44.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.4)\nCollecting tokenizers<0.21,>=0.20 (from transformers>=4.44.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: docstring-parser>=0.16 in /opt/conda/lib/python3.10/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\nRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.7.1)\nCollecting shtab>=1.5.6 (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\nCollecting triton (from unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\nCollecting accelerate>=0.34.1 (from unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading accelerate-1.1.0-py3-none-any.whl.metadata (19 kB)\nCollecting trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading trl-0.12.0-py3-none-any.whl.metadata (10 kB)\nCollecting peft!=0.11.0,>=0.7.1 (from unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.7.4)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.18.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\nDownloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.46.1-py3-none-any.whl (10.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tyro-0.8.14-py3-none-any.whl (109 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.8/109.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading unsloth_zoo-2024.11.0-py3-none-any.whl (25 kB)\nDownloading accelerate-1.1.0-py3-none-any.whl (333 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m333.2/333.2 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading peft-0.13.2-py3-none-any.whl (320 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\nDownloading tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading trl-0.12.0-py3-none-any.whl (310 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.2/310.2 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: unsloth\n  Building wheel for unsloth (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for unsloth: filename=unsloth-2024.10.7-py3-none-any.whl size=164377 sha256=d3e66df24e506c79880901a7b774730b1331554de8883aae482a31f99cc71795\n  Stored in directory: /tmp/pip-ephem-wheel-cache-mdsf8lk1/wheels/ed/d4/e9/76fb290ee3df0a5fc21ce5c2c788e29e9607a2353d8342fd0d\nSuccessfully built unsloth\nInstalling collected packages: unsloth, triton, shtab, hf-transfer, tyro, tokenizers, bitsandbytes, accelerate, transformers, trl, peft, unsloth-zoo\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.19.1\n    Uninstalling tokenizers-0.19.1:\n      Successfully uninstalled tokenizers-0.19.1\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.33.0\n    Uninstalling accelerate-0.33.0:\n      Successfully uninstalled accelerate-0.33.0\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.44.0\n    Uninstalling transformers-4.44.0:\n      Successfully uninstalled transformers-4.44.0\nSuccessfully installed accelerate-1.1.0 bitsandbytes-0.44.1 hf-transfer-0.1.8 peft-0.13.2 shtab-1.7.1 tokenizers-0.20.1 transformers-4.46.1 triton-3.1.0 trl-0.12.0 tyro-0.8.14 unsloth-2024.10.7 unsloth-zoo-2024.11.0\nCollecting xformers\n  Downloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\nRequirement already satisfied: trl in /opt/conda/lib/python3.10/site-packages (0.12.0)\nRequirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.13.2)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (1.1.0)\nRequirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.44.1)\nRequirement already satisfied: triton in /opt/conda/lib/python3.10/site-packages (3.1.0)\nDownloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: xformers\nSuccessfully installed xformers-0.0.28.post3\n","output_type":"stream"}]},{"cell_type":"markdown","source":"* We support Llama, Mistral, Phi-3, Gemma, Yi, DeepSeek, Qwen, TinyLlama, Vicuna, Open Hermes etc\n* We support 16bit LoRA or 4bit QLoRA. Both 2x faster.\n* `max_seq_length` can be set to anything, since we do automatic RoPE Scaling via [kaiokendev's](https://kaiokendev.github.io/til) method.\n* [**NEW**] We make Gemma-2 9b / 27b **2x faster**! See our [Gemma-2 9b notebook](https://colab.research.google.com/drive/1vIrqH5uYDQwsJ4-OO3DErvuv4pBgVwk4?usp=sharing)\n* [**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)\n* [**NEW**] We make Mistral NeMo 12B 2x faster and fit in under 12GB of VRAM! [Mistral NeMo notebook](https://colab.research.google.com/drive/17d3U-CAIwzmbDRqbZ9NnpHxCkmXB6LZ0?usp=sharing)","metadata":{"id":"r2v_X2fA0Df5"}},{"cell_type":"code","source":"!pip uninstall -y xformers\n!pip install git+https://github.com/facebookresearch/xformers.git@main","metadata":{"execution":{"iopub.status.busy":"2024-11-02T08:10:02.794253Z","iopub.execute_input":"2024-11-02T08:10:02.794944Z","iopub.status.idle":"2024-11-02T08:16:55.927640Z","shell.execute_reply.started":"2024-11-02T08:10:02.794902Z","shell.execute_reply":"2024-11-02T08:16:55.925936Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Found existing installation: xformers 0.0.28.post3\nUninstalling xformers-0.0.28.post3:\n  Successfully uninstalled xformers-0.0.28.post3\nCollecting git+https://github.com/facebookresearch/xformers.git@main\n  Cloning https://github.com/facebookresearch/xformers.git (to revision main) to /tmp/pip-req-build-9e4zu38k\n  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/xformers.git /tmp/pip-req-build-9e4zu38k\n  Resolved https://github.com/facebookresearch/xformers.git to commit de742ec3d64bd83b1184cc043e541f15d270c148\n  Running command git submodule update --init --recursive -q\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch>=2.4 in /opt/conda/lib/python3.10/site-packages (from xformers==0.0.29+de742ec.d20241102) (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xformers==0.0.29+de742ec.d20241102) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.4->xformers==0.0.29+de742ec.d20241102) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4->xformers==0.0.29+de742ec.d20241102) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.4->xformers==0.0.29+de742ec.d20241102) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.4->xformers==0.0.29+de742ec.d20241102) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4->xformers==0.0.29+de742ec.d20241102) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=2.4->xformers==0.0.29+de742ec.d20241102) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.4->xformers==0.0.29+de742ec.d20241102) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.4->xformers==0.0.29+de742ec.d20241102) (1.3.0)\nBuilding wheels for collected packages: xformers\n  Building wheel for xformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for xformers: filename=xformers-0.0.29+de742ec.d20241102-cp310-cp310-linux_x86_64.whl size=6171687 sha256=beea9e85af9c7bad66d6031a4651eb3bedb8a4271a5c4c5ee2f32098c5f6ff10\n  Stored in directory: /tmp/pip-ephem-wheel-cache-t_z6wpi_/wheels/c6/e1/85/5f7882fdae87b53eb35001eb734a2606aa0fb5475446543684\nSuccessfully built xformers\nInstalling collected packages: xformers\nSuccessfully installed xformers-0.0.29+de742ec.d20241102\n","output_type":"stream"}]},{"cell_type":"code","source":"!wandb login ae1c666b1cb970ae400e2f7e647d878eb2cd640b","metadata":{"execution":{"iopub.status.busy":"2024-11-02T08:16:55.930674Z","iopub.execute_input":"2024-11-02T08:16:55.931148Z","iopub.status.idle":"2024-11-02T08:16:59.606266Z","shell.execute_reply.started":"2024-11-02T08:16:55.931101Z","shell.execute_reply":"2024-11-02T08:16:59.605226Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"}]},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nimport torch\nmax_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\ndtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\nload_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n\n# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\nfourbit_models = [\n    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 2x faster\n    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # 4bit for 405b!\n    \"unsloth/Mistral-Small-Instruct-2409\",     # Mistral 22b 2x faster!\n    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n    \"unsloth/Phi-3-medium-4k-instruct\",\n    \"unsloth/gemma-2-9b-bnb-4bit\",\n    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n\n    \"unsloth/Llama-3.2-1B-bnb-4bit\",           # NEW! Llama 3.2 models\n    \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\",\n    \"unsloth/Llama-3.2-3B-bnb-4bit\",\n    \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\",\n] # More models at https://huggingface.co/unsloth\n # More models at https://huggingface.co/unsloth\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/Llama-3.2-3B-bnb-4bit\",\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n#     token = \"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\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281,"referenced_widgets":["77526812ddf044d197cb0edc9fd63a3a","c782d2fe68a34cdcb9dee1faf7bbe28a","cbd0517b54a24958bd598303e14c26a0","25e98a708c224625a1f3cb0bfbf89846","e17e7e1c7b40476d9d399f1cde9a66db","c360584b8a0447aab3cfd3d8d68ec13c","e70e2d40bb144cd49ad402c0de78ab28","827f5ad5bc9b4e3c9e80504c22a34289","5cac9c43751947b0a4cd170b25612af7","1acfe7f5763d48589fc91e3340fb6633","7e69eda079d34d5a8237b9891c54dde4","e420322e6cfa49be899e60d09ac79b34","68b9147bcdc9464bbce3be306f8cd71c","a4fd216bd9174221a05e5e5fca9dcc02","1d6e29dea712405e91a65f5d509d72c0","3ce01164e44b4c1c83cf96797afacd63","4a4146355038498188a661e06b9e640b","42bc292dd9314507a0d630e882b2d9a8","028ce3f8d4d84659b102a011fcfecb55","5dbe42dd1dc6463bb608195024f5f334","9cf3f0eca84241b296bc63cc95adb853","25bc8360bfdb45b8adfe48af80c054b7","f9a04a91b96e462dac19311d9714de87","a4274391df874147877a211109183853","8d13dd8a82c44e01bde4743b12a80252","42b62a340891454c9a7b95324530000c","284b481cd3cf4b65b52f0a6cd09905d1","94f343cb1bc945cea1d5d0e96a279ea7","44cbf1256cf947dcaff5ba55d5a8c9f7","8140f40d66dc4a5fb860a715abb0c79e","70e26ca3e63243d2b1619b26a87f3436","f5cbad8828d74ff0886effb5d5cd60b4","02c7c8b7a1d140efb1cbe287f35c6da5","dce557af52704211b102937aea9b22d9","b771513fd36b4ce59b1d7b2cd5d16d4b","d6993d2f38ec492b8b605ec4a9da7462","f2ff20f18b6d480ebd5836b81afb18f5","5e061ff7baf942879af6e8e87caa0f0a","ffdc2927262f4a63a89b13ec92a5e8cb","1d1cc1b087e54b51b824cae9b5dda375","f470eea92b0144b08b43de64b2b92eab","c331c89b2b03424681c99b648861fef1","6f2a9bb834984efd822c49bd8a976bc5","f434e0ea14c646bd8e6032e963b5ebfa","f932a4502a254b8d88c52bcd85564045","e05023f3f9bd4caf8683c0791151b1d8","100b69e7e968428fbd6a6048928840d8","fca0088e1a6b4fc08aea6d9c041365dd","7a644778e46f42e5b6f77ad2352ef55b","bfa9ed2ce8df4b519b81a8055ec35b96","50007b0f16bf48c08474a16a2f516015","35c0a79f2e7942539ca12d2f8830ad28","c35a06950d9f4305a43bc8dbaf7e095d","f4243bb9d55044d9b6d98b28af98b8a5","19d07031c6404ef597b526f7a736fb4a"]},"id":"QmUBVEnvCDJv","outputId":"6c3d8509-fe6e-4695-8603-53f2243f89ba","execution":{"iopub.status.busy":"2024-11-02T08:16:59.609716Z","iopub.execute_input":"2024-11-02T08:16:59.610051Z","iopub.status.idle":"2024-11-02T08:17:34.131569Z","shell.execute_reply.started":"2024-11-02T08:16:59.610017Z","shell.execute_reply":"2024-11-02T08:17:34.130175Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n==((====))==  Unsloth 2024.10.7: Fast Llama patching. Transformers = 4.46.1.\n   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\nO^O/ \\_/ \\    Pytorch: 2.4.0. CUDA = 7.5. CUDA Toolkit = 12.3.\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29+de742ec.d20241102. FA2 = False]\n \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b645c2f617f94270baa43d27aab97ff6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/121 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fef3cccec29644298e427f5edf285e54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ca8d82ca0964698b2a3dcd496bf8b51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc6d290619ce4bae892bc46b4b3a88b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/459 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ad105bf713d4c43accf489e8dc48888"}},"metadata":{}}]},{"cell_type":"markdown","source":"We now add LoRA adapters so we only need to update 1 to 10% of all parameters!","metadata":{"id":"SXd9bTZd1aaL"}},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 16,\n    lora_dropout = 0, # Supports any, but = 0 is optimized\n    bias = \"none\",    # Supports any, but = \"none\" is optimized\n    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n    random_state = 3407,\n    use_rslora = False,  # We support rank stabilized LoRA\n    loftq_config = None, # And LoftQ\n)","metadata":{"id":"6bZsfBuZDeCL","execution":{"iopub.status.busy":"2024-11-02T08:17:34.133410Z","iopub.execute_input":"2024-11-02T08:17:34.133746Z","iopub.status.idle":"2024-11-02T08:17:40.040805Z","shell.execute_reply.started":"2024-11-02T08:17:34.133695Z","shell.execute_reply":"2024-11-02T08:17:40.039657Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"Unsloth 2024.10.7 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<a name=\"Data\"></a>\n### Data Prep\nWe now use the Alpaca dataset from [yahma](https://huggingface.co/datasets/yahma/alpaca-cleaned), which is a filtered version of 52K of the original [Alpaca dataset](https://crfm.stanford.edu/2023/03/13/alpaca.html). You can replace this code section with your own data prep.\n\n**[NOTE]** To train only on completions (ignoring the user's input) read TRL's docs [here](https://huggingface.co/docs/trl/sft_trainer#train-on-completions-only).\n\n**[NOTE]** Remember to add the **EOS_TOKEN** to the tokenized output!! Otherwise you'll get infinite generations!\n\nIf you want to use the `llama-3` template for ShareGPT datasets, try our conversational [notebook](https://colab.research.google.com/drive/1XamvWYinY6FOSX9GLvnqSjjsNflxdhNc?usp=sharing).\n\nFor text completions like novel writing, try this [notebook](https://colab.research.google.com/drive/1ef-tab5bhkvWmBOObepl1WgJvfvSzn5Q?usp=sharing).","metadata":{"id":"vITh0KVJ10qX"}},{"cell_type":"code","source":"import math\nalpaca_prompt = \"\"\"###\nUse the given schema to write an SQL query that fetches the appropriate data from the database.  Only provide the SQL query, with no explanation.\n###\nExample:\nQuestion: \"Find all employees in the Sales department.\"\nSchema:\nemployees(id, name, department, salary, hire_date)\nSQL Query:\nSELECT * FROM employees WHERE department = 'Sales';\n\n###\nQuestion : {}\n###\nSchema :{} \n###   \nSQL Query : {} \n\"\"\"\n\nEOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\ndef formatting_prompts_func(examples):\n    question = examples[\"question\"]\n    inputs       = examples[\"db_id\"]\n    outputs      = examples[\"query\"]\n    texts = []\n    for instruction, input, output in zip(question, inputs, outputs):\n        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n        text = alpaca_prompt.format(question, input, output) + EOS_TOKEN\n        texts.append(text)\n    return { \"text\" : texts, }\npass\nimport pandas as pd\nfrom datasets import Dataset\n\nsplits = {'train': 'spider/train-00000-of-00001.parquet', 'validation': 'spider/validation-00000-of-00001.parquet'}\ndf = pd.read_parquet(\"hf://datasets/xlangai/spider/\" + splits[\"train\"])\ndf=df.drop(['query_toks','query_toks_no_value','question_toks'],axis=1)\ndf=df[0:40]\ndataset = Dataset.from_pandas(df)\ndataset = dataset.map(formatting_prompts_func, batched = True,)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["dfbebab4648f4587a2b69c2b967c8d53","bc16617c16dd43eaad83b866e0650181","a0940ce1cfdf49f1a2218bdbe0881a66","c5f80e90b30441e3b3e6fe6c27a3b448","f545d721c72547f2a2eacc8a5274f88a","c6c2d4eec6214735bffdcbaca19d16d3","2880c91657f54d2b95e538144725a590","a9159af7acc2451c85d7dc86f6395cd9","ef20cb6c51664c3d8d6a5aab7382e2e0","74acd0bf7b9541d79beeffa9abe838f0","04e015954efe4efd9247fdf5a0cd1187"]},"id":"LjY75GoYUCB8","outputId":"962e0fe6-c0db-4056-e591-ce248ff0876c","execution":{"iopub.status.busy":"2024-11-02T08:17:40.042293Z","iopub.execute_input":"2024-11-02T08:17:40.042593Z","iopub.status.idle":"2024-11-02T08:17:40.917216Z","shell.execute_reply.started":"2024-11-02T08:17:40.042562Z","shell.execute_reply":"2024-11-02T08:17:40.916070Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/40 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"677d7345d34041fa9dad67504d108794"}},"metadata":{}}]},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom unsloth import is_bfloat16_supported\n\ntrainer = SFTTrainer(\n    model = model,\n    tokenizer = tokenizer,\n    train_dataset = dataset,\n    dataset_text_field = \"text\",\n    max_seq_length = max_seq_length,\n    dataset_num_proc = 2,\n    packing = False, # Can make training 5x faster for short sequences.\n    args = TrainingArguments(\n        per_device_train_batch_size = 1,\n        gradient_accumulation_steps = 4,\n        warmup_steps = 5,\n        # num_train_epochs = 1, # Set this for 1 full training run.\n        max_steps = 20,\n        learning_rate = 2e-4,\n        fp16 = not is_bfloat16_supported(),\n        bf16 = is_bfloat16_supported(),\n        logging_steps = 1,\n        optim = \"adamw_8bit\",\n        weight_decay = 0.01,\n        lr_scheduler_type = \"linear\",\n        seed = 3417,\n        output_dir = \"outputs\",\n    ),\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["cbbd1295d909478fa1560ae5c6780373","7c67acc6723d4eeebb89591c78b8d742","92f1f01de9ea4963a4a8f8bb56335a14","71d1ec57a60e4f159dde8fe5423625ed","239990396a4b4588827e35a605076db9","ab4f47a0adad424996ccf8b7c8660a5d","c5e696ab8e5145ce8919a69ce0a85cd3","5c626e6cacb74a098f1d173bb159bd78","050a4ce725a446189834b42410b67811","5a55640dd1b646d6892dc2f442366be7","f8db0f897e2e45d18093f10f14d0527d"]},"id":"95_Nn-89DhsL","outputId":"103db0d1-4c25-4bf6-ab6d-87ff8dfaacc2","execution":{"iopub.status.busy":"2024-11-02T08:17:40.918954Z","iopub.execute_input":"2024-11-02T08:17:40.919390Z","iopub.status.idle":"2024-11-02T08:17:47.917423Z","shell.execute_reply.started":"2024-11-02T08:17:40.919341Z","shell.execute_reply":"2024-11-02T08:17:47.916265Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=2):   0%|          | 0/40 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6d4b37acfbf413eac0a4038167cc590"}},"metadata":{}},{"name":"stderr","text":"max_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<a name=\"Train\"></a>\n### Train the model\nNow let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!","metadata":{"id":"idAEIeSQ3xdS"}},{"cell_type":"code","source":"#@title Show current memory stats\ngpu_stats = torch.cuda.get_device_properties(0)\nstart_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nmax_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\nprint(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\nprint(f\"{start_gpu_memory} GB of memory reserved.\")","metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"id":"2ejIt2xSNKKp","outputId":"dcf21f52-dd99-4695-f5ee-00c3829fd9b4","execution":{"iopub.status.busy":"2024-11-02T08:17:47.919180Z","iopub.execute_input":"2024-11-02T08:17:47.919565Z","iopub.status.idle":"2024-11-02T08:17:47.927913Z","shell.execute_reply.started":"2024-11-02T08:17:47.919523Z","shell.execute_reply":"2024-11-02T08:17:47.926671Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"GPU = Tesla T4. Max memory = 14.741 GB.\n2.635 GB of memory reserved.\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer_stats = trainer.train()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"yqxqAZ7KJ4oL","outputId":"9c6b1dda-77fe-4239-95b9-b9d59592a543","execution":{"iopub.status.busy":"2024-11-02T08:17:47.929547Z","iopub.execute_input":"2024-11-02T08:17:47.929979Z","iopub.status.idle":"2024-11-02T08:19:43.980194Z","shell.execute_reply.started":"2024-11-02T08:17:47.929940Z","shell.execute_reply":"2024-11-02T08:19:43.979263Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n   \\\\   /|    Num examples = 40 | Num Epochs = 2\nO^O/ \\_/ \\    Batch size per device = 1 | Gradient Accumulation steps = 4\n\\        /    Total batch size = 4 | Total steps = 20\n \"-____-\"     Number of trainable parameters = 24,313,856\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbv-gaurav4\u001b[0m (\u001b[33mbv-gaurav4-people\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.18.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241102_081753-tqjjilde</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/bv-gaurav4-people/huggingface/runs/tqjjilde' target=\"_blank\">outputs</a></strong> to <a href='https://wandb.ai/bv-gaurav4-people/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/bv-gaurav4-people/huggingface' target=\"_blank\">https://wandb.ai/bv-gaurav4-people/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/bv-gaurav4-people/huggingface/runs/tqjjilde' target=\"_blank\">https://wandb.ai/bv-gaurav4-people/huggingface/runs/tqjjilde</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [20/20 01:24, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.970700</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.958700</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.935300</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.893400</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.813300</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>1.707500</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>1.557200</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>1.391100</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>1.297300</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>1.166800</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>1.019800</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.913700</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.783800</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.668300</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.580700</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.511400</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.463500</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.395900</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.367300</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.323200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"#@title Show final memory and time stats\nused_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nused_memory_for_lora = round(used_memory - start_gpu_memory, 3)\nused_percentage = round(used_memory         /max_memory*100, 3)\nlora_percentage = round(used_memory_for_lora/max_memory*100, 3)\nprint(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\nprint(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\nprint(f\"Peak reserved memory = {used_memory} GB.\")\nprint(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\nprint(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\nprint(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pCqnaKmlO1U9","outputId":"79d03e2a-497e-435e-f2cb-cbaad2d2c911","execution":{"iopub.status.busy":"2024-11-02T08:19:43.983299Z","iopub.execute_input":"2024-11-02T08:19:43.983620Z","iopub.status.idle":"2024-11-02T08:19:43.993928Z","shell.execute_reply.started":"2024-11-02T08:19:43.983585Z","shell.execute_reply":"2024-11-02T08:19:43.992922Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"112.7954 seconds used for training.\n1.88 minutes used for training.\nPeak reserved memory = 3.467 GB.\nPeak reserved memory for training = 0.832 GB.\nPeak reserved memory % of max memory = 23.519 %.\nPeak reserved memory for training % of max memory = 5.644 %.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<a name=\"Inference\"></a>\n### Inference\nLet's run the model! You can change the instruction and input - leave the output blank!\n\n**[NEW] Try 2x faster inference in a free Colab for Llama-3.1 8b Instruct [here](https://colab.research.google.com/drive/1T-YBVfnphoVc8E2E854qF3jdia2Ll2W2?usp=sharing)**","metadata":{"id":"ekOmTR1hSNcr"}},{"cell_type":"code","source":"# alpaca_prompt = Copied from above\nFastLanguageModel.for_inference(model) # Enable native 2x faster inference\ninputs = tokenizer(\n[\n    alpaca_prompt.format(\n        \"what is the  average vote of the states\", # instruction\n        \"election_res(id,state_name,assembly_constituency_name,nota_vote,candidate_name,party_name,votes_secured,parlimentary_constituency_name)  where votes_secured is total vote secured by the party\", # input\n        \"\", # output - leave this blank for generation!\n    )\n], return_tensors = \"pt\").to(\"cuda\")\n\n\noutputs = model.generate(**inputs, max_new_tokens=40)\ngenerated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(\"Generated output:\", generated_text)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kR3gIAX-SM2q","outputId":"9be1204b-7407-46cb-9bdf-1e75c5efe52a","execution":{"iopub.status.busy":"2024-11-02T09:09:55.658523Z","iopub.execute_input":"2024-11-02T09:09:55.658946Z","iopub.status.idle":"2024-11-02T09:09:57.604119Z","shell.execute_reply.started":"2024-11-02T09:09:55.658904Z","shell.execute_reply":"2024-11-02T09:09:57.603108Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Generated output: ###\nUse the given schema to write an SQL query that fetches the appropriate data from the database.  Only provide the SQL query, with no explanation.\n###\nExample:\nQuestion: \"Find all employees in the Sales department.\"\nSchema:\nemployees(id, name, department, salary, hire_date)\nSQL Query:\nSELECT * FROM employees WHERE department = 'Sales';\n\n###\nQuestion : what is the  average vote of the states\n###\nSchema :election_res(id,state_name,assembly_constituency_name,nota_vote,candidate_name,party_name,votes_secured,parlimentary_constituency_name)  where votes_secured is total vote secured by the party \n###   \nSQL Query :  \nSELECT state_name,AVG(votes_secured) FROM election_res GROUP BY state_name ORDER BY AVG(votes_secured) DESC;\n","output_type":"stream"}]},{"cell_type":"code","source":"import math\nalpaca_prompt2 =\"\"\" ### Inference Generation Prompt ###\n\nAnalyze the query results to provide insights into the data with respect to the question and query provided.\nQuestion: {}\nQuery: {}\nData:{}\n\nInference:\n\n\"\"\"\n","metadata":{"execution":{"iopub.status.busy":"2024-11-02T09:39:59.507186Z","iopub.execute_input":"2024-11-02T09:39:59.508158Z","iopub.status.idle":"2024-11-02T09:39:59.514051Z","shell.execute_reply.started":"2024-11-02T09:39:59.508115Z","shell.execute_reply":"2024-11-02T09:39:59.512687Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"lol=\"\"\"('Punjab', Decimal('5417.6787'))\n('NCT OF Delhi', Decimal('5255.0329'))\n('Himachal Pradesh', Decimal('4927.0771'))\n('Meghalaya', Decimal('4701.3681'))\n('Nagaland', Decimal('4167.2208'))\n('Goa', Decimal('3494.9375'))\n('Tripura', Decimal('3071.2652'))\"\"\"\nquestion=\"what is the  average vote of the states\"","metadata":{"execution":{"iopub.status.busy":"2024-11-02T09:40:02.160769Z","iopub.execute_input":"2024-11-02T09:40:02.161606Z","iopub.status.idle":"2024-11-02T09:40:02.167579Z","shell.execute_reply.started":"2024-11-02T09:40:02.161565Z","shell.execute_reply":"2024-11-02T09:40:02.166293Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"alpaca_prompt2.format(question,lol,\"SELECT state_name, AVG(votes_secured) FROM election_res GROUP BY state_name ORDER BY AVG(votes_secured) DESC;\")","metadata":{"execution":{"iopub.status.busy":"2024-11-02T09:40:03.460310Z","iopub.execute_input":"2024-11-02T09:40:03.460809Z","iopub.status.idle":"2024-11-02T09:40:03.469411Z","shell.execute_reply.started":"2024-11-02T09:40:03.460764Z","shell.execute_reply":"2024-11-02T09:40:03.468141Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"\" ### Inference Generation Prompt ###\\n\\nAnalyze the query results to provide insights into the data with respect to the question and query provided.\\nQuestion: what is the  average vote of the states\\nData:('Punjab', Decimal('5417.6787'))\\n('NCT OF Delhi', Decimal('5255.0329'))\\n('Himachal Pradesh', Decimal('4927.0771'))\\n('Meghalaya', Decimal('4701.3681'))\\n('Nagaland', Decimal('4167.2208'))\\n('Goa', Decimal('3494.9375'))\\n('Tripura', Decimal('3071.2652'))\\nQuery: SELECT state_name, AVG(votes_secured) FROM election_res GROUP BY state_name ORDER BY AVG(votes_secured) DESC;\\nInference:\\n\""},"metadata":{}}]},{"cell_type":"code","source":"# alpaca_prompt = Copied from above\nFastLanguageModel.for_inference(model) # Enable native 2x faster inference\ninputs = tokenizer(\n[\nalpaca_prompt2.format(question,\"SELECT state_name, AVG(votes_secured) FROM election_res GROUP BY state_name ORDER BY AVG(votes_secured) DESC;\",lol)\n], return_tensors = \"pt\").to(\"cuda\")\n\n\noutputs = model.generate(**inputs, max_new_tokens=100)\ngenerated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(\"Generated output:\", generated_text)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-02T09:47:18.607322Z","iopub.execute_input":"2024-11-02T09:47:18.607728Z","iopub.status.idle":"2024-11-02T09:47:24.996398Z","shell.execute_reply.started":"2024-11-02T09:47:18.607692Z","shell.execute_reply":"2024-11-02T09:47:24.995343Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"Generated output:  ### Inference Generation Prompt ###\n\nAnalyze the query results to provide insights into the data with respect to the question and query provided.\nQuestion: what is the  average vote of the states\nData:SELECT state_name, AVG(votes_secured) FROM election_res GROUP BY state_name ORDER BY AVG(votes_secured) DESC;\nQuery: ('Punjab', Decimal('5417.6787'))\n('NCT OF Delhi', Decimal('5255.0329'))\n('Himachal Pradesh', Decimal('4927.0771'))\n('Meghalaya', Decimal('4701.3681'))\n('Nagaland', Decimal('4167.2208'))\n('Goa', Decimal('3494.9375'))\n('Tripura', Decimal('3071.2652'))\nInference:\nThe average vote of the states is increasing from west to east. The state with the highest average vote is Punjab with 5417.6787 votes, while the state with the lowest average vote is Tripura with 3071.2652 votes. The states with the highest average votes are located in the western part of the country, while the states with the lowest average votes are located in the eastern part of the country. This may be due to the fact that the western states have more resources\n","output_type":"stream"}]},{"cell_type":"code","source":"def exxtraction(text):\n    text=text.replace(\"\\n\",\" \")\n    text=text.split(\"###\")\n    text=text[5]\n    text=text.split(\":\")\n    return text[1]","metadata":{"execution":{"iopub.status.busy":"2024-11-02T08:22:16.359582Z","iopub.execute_input":"2024-11-02T08:22:16.359944Z","iopub.status.idle":"2024-11-02T08:22:16.367480Z","shell.execute_reply.started":"2024-11-02T08:22:16.359913Z","shell.execute_reply":"2024-11-02T08:22:16.366163Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def exxtraction2(text):\n    text=text.replace(\"\\n\",\" \")\n    text=text.split(\":\")\n    return text[len(text)-1]","metadata":{"execution":{"iopub.status.busy":"2024-11-02T09:22:42.551286Z","iopub.execute_input":"2024-11-02T09:22:42.552013Z","iopub.status.idle":"2024-11-02T09:22:42.558672Z","shell.execute_reply.started":"2024-11-02T09:22:42.551967Z","shell.execute_reply":"2024-11-02T09:22:42.557457Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"exxtraction2(generated_text)","metadata":{"execution":{"iopub.status.busy":"2024-11-02T09:22:50.481012Z","iopub.execute_input":"2024-11-02T09:22:50.481486Z","iopub.status.idle":"2024-11-02T09:22:50.490702Z","shell.execute_reply.started":"2024-11-02T09:22:50.481444Z","shell.execute_reply":"2024-11-02T09:22:50.489404Z"},"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"' The state with the highest average number of votes is Punjab with 5417.6787 votes, followed by NCT of Delhi with 5255.0329 votes, Himachal Pradesh with 4927.0771 votes, Meghalaya with 4701.3681 votes, Nagaland with 4167.2208 votes, Goa with 3494.9375 votes, and Tripura with 3071.2652 votes. '"},"metadata":{}}]},{"cell_type":"code","source":"!pip install pyngrok","metadata":{"execution":{"iopub.status.busy":"2024-11-02T08:20:32.704719Z","iopub.execute_input":"2024-11-02T08:20:32.705682Z","iopub.status.idle":"2024-11-02T08:20:47.951904Z","shell.execute_reply.started":"2024-11-02T08:20:32.705626Z","shell.execute_reply":"2024-11-02T08:20:47.950516Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pyngrok in /opt/conda/lib/python3.10/site-packages (7.2.0)\nRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.10/site-packages (from pyngrok) (6.0.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"from flask import Flask, request, jsonify\nfrom pyngrok import ngrok\nfrom transformers import TextStreamer\n\napp = Flask(__name__)\n\nngrok.set_auth_token(\"2OGrdSJJOMfZVL4lsN9ES4a7NQX_3mHgdmcwYPK4ZypaRvqca\")  # Replace with your actual Ngrok auth token\n\n@app.route(\"/message\", methods=[\"POST\"])\ndef final_message():\n    data = request.json\n    question=data['question']\n    schema=data['table']\n    query=data['query']\n    # alpaca_prompt = Copied from above\n    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n    inputs = tokenizer(\n    [\n    alpaca_prompt2.format(question,schema,query)\n    ], return_tensors = \"pt\").to(\"cuda\")\n\n\n    outputs = model.generate(**inputs, max_new_tokens=200)\n    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    print(generated_text)\n    return jsonify(message=exxtraction2(generated_text))\n    \n@app.route(\"/\", methods=[\"POST\"])\ndef hello_world():\n    data = request.json\n    question=data['question']\n    schema=data['schema']\n    \n    print(\"Received data:\", data)  \n    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n    inputs = tokenizer(\n    [\n        alpaca_prompt.format(\n            question, # instruction\n            schema, # input\n            \"\", # output - leave this blank for generation!\n        )\n    ], return_tensors = \"pt\").to(\"cuda\")\n\n\n    outputs = model.generate(**inputs, max_new_tokens=40)\n    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    print(exxtraction(generated_text))\n    return jsonify(message=exxtraction(generated_text))  \nif __name__ == \"__main__\":\n    public_url = ngrok.connect(5000, bind_tls=True)  \n    print(f\" * ngrok tunnel \\\"{public_url}\\\" -> \\\"http://127.0.0.1:5000/\\\"\")\n\n    app.run()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-02T09:47:40.566781Z","iopub.execute_input":"2024-11-02T09:47:40.567267Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":" * ngrok tunnel \"NgrokTunnel: \"https://6ba8-35-196-242-202.ngrok-free.app\" -> \"http://localhost:5000\"\" -> \"http://127.0.0.1:5000/\"\n * Serving Flask app '__main__'\n * Debug mode: off\nReceived data: {'question': 'what is the  average vote of the states', 'schema': 'election_res(id,state_name,assembly_constituency_name,nota_vote,candidate_name,party_name,votes_secured,parlimentary_constituency_name)  where votes_secured is total vote secured by the party'}\n   SELECT state_name,AVG(votes_secured) FROM election_res GROUP BY state_name ORDER BY AVG(votes_secured) DESC;\n ### Inference Generation Prompt ###\n\nAnalyze the query results to provide insights into the data with respect to the question and query provided.\nQuestion: what is the  average vote of the states\nData:\n('Odisha', Decimal('19219.4778'))\n('Dadra & Nagar Haveli', Decimal('17815.9091'))\n('Uttar Pradesh', Decimal('17349.3433'))\n('West Bengal', Decimal('17336.3694'))\n('Rajasthan', Decimal('16028.6290'))\n('Andhra Pradesh', Decimal('13846.0381'))\n('Andaman & Nicobar Islands', Decimal('13711.2667'))\n('Assam', Decimal('13400.0785'))\n('Kerala', Decimal('12717.7867'))\n('Chandigarh', Decimal('12552.3889'))\n('Jharkhand', Decimal('11179.3687'))\n('Gujarat', Decimal('10986.6750'))\n('Daman & Diu', Decimal('10744.2500'))\n('Madhya Pradesh', Decimal('10520.7264'))\n('Bihar', Decimal('10454.4355'))\n('Maharashtra', Decimal('10256.0369'))\n('Chhattisgarh', Decimal('9742.5604'))\n('Karnataka', Decimal('9101.2568'))\n('Tamil Nadu', Decimal('8360.5227'))\n('Lakshadweep', Decimal('7796.3333'))\n('Uttarakhand', Decimal('6493.3434'))\n('Haryana', Decimal('6271.2701'))\n('Telangana', Decimal('5944.9507'))\n('Punjab', Decimal('5417.6787'))\n('NCT OF Delhi', Decimal('5255.0329'))\n('Himachal Pradesh', Decimal('4927.0771'))\n('Meghalaya', Decimal('4701.3681'))\n('Nagaland', Decimal('4167.2208'))\n('Goa', Decimal('3494.9375'))\n('Tripura', Decimal('3071.2652'))\n('Manipur', Decimal('2779.8090'))\n('Jammu & Kashmir', Decimal('2628.3157'))\n('Mizoram', Decimal('2059.5292'))\n('Arunachal Pradesh', Decimal('1693.0328'))\n('Puducherry', Decimal('1440.8519'))\n('Sikkim', Decimal('990.0968'))\nQuery:    SELECT state_name,AVG(votes_secured) FROM election_res GROUP BY state_name ORDER BY AVG(votes_secured) DESC;\nInference:\nThe average vote of the states is highest in Maharashtra with 10256.0369 and lowest in Arunachal Pradesh with 1693.0328.\n\nReceived data: {'question': 'what is the  average vote of the states', 'schema': 'election_res(id,state_name,assembly_constituency_name,nota_vote,candidate_name,party_name,votes_secured,parlimentary_constituency_name)  where votes_secured is total vote secured by the party'}\n   SELECT state_name,AVG(votes_secured) FROM election_res GROUP BY state_name ORDER BY AVG(votes_secured) DESC;\nReceived data: {'question': 'what is the  average vote of the states', 'schema': 'election_res(id,state_name,assembly_constituency_name,nota_vote,candidate_name,party_name,votes_secured,parlimentary_constituency_name)  where votes_secured is total vote secured by the party'}\n   SELECT state_name,AVG(votes_secured) FROM election_res GROUP BY state_name ORDER BY AVG(votes_secured) DESC;\n ### Inference Generation Prompt ###\n\nAnalyze the query results to provide insights into the data with respect to the question and query provided.\nQuestion: what is the  average vote of the states\nData:                            0           1\n0                      Odisha  19219.4778\n1        Dadra & Nagar Haveli  17815.9091\n2               Uttar Pradesh  17349.3433\n3                 West Bengal  17336.3694\n4                   Rajasthan  16028.6290\n5              Andhra Pradesh  13846.0381\n6   Andaman & Nicobar Islands  13711.2667\n7                       Assam  13400.0785\n8                      Kerala  12717.7867\n9                  Chandigarh  12552.3889\n10                  Jharkhand  11179.3687\n11                    Gujarat  10986.6750\n12                Daman & Diu  10744.2500\n13             Madhya Pradesh  10520.7264\n14                      Bihar  10454.4355\n15                Maharashtra  10256.0369\n16               Chhattisgarh   9742.5604\n17                  Karnataka   9101.2568\n18                 Tamil Nadu   8360.5227\n19                Lakshadweep   7796.3333\n20                Uttarakhand   6493.3434\n21                    Haryana   6271.2701\n22                  Telangana   5944.9507\n23                     Punjab   5417.6787\n24               NCT OF Delhi   5255.0329\n25           Himachal Pradesh   4927.0771\n26                  Meghalaya   4701.3681\n27                   Nagaland   4167.2208\n28                        Goa   3494.9375\n29                    Tripura   3071.2652\n30                    Manipur   2779.8090\n31            Jammu & Kashmir   2628.3157\n32                    Mizoram   2059.5292\n33          Arunachal Pradesh   1693.0328\n34                 Puducherry   1440.8519\n35                     Sikkim    990.0968\nQuery:    SELECT state_name,AVG(votes_secured) FROM election_res GROUP BY state_name ORDER BY AVG(votes_secured) DESC;\nInference:\nThe average vote of the states is  17336.3694. The state with the highest average vote is West Bengal with 17336.3694 votes, while the state with the lowest average vote is Sikkim with 990.0968 votes.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# alpaca_prompt = Copied from above\nFastLanguageModel.for_inference(model) # Enable native 2x faster inference\ninputs = tokenizer(\n[\n    alpaca_prompt.format(\n        \"North Korea Delegation Meets With South Korean Officials\", # instruction\n        \"South Korea declares end to MERS outbreak\", # input\n        \"\", # output - leave this blank for generation!\n    )\n], return_tensors = \"pt\").to(\"cuda\")\n\nfrom transformers import TextStreamer\ntext_streamer = TextStreamer(tokenizer)\n_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 100)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e2pEuRb1r2Vg","outputId":"a00312ad-5707-4cbf-973d-8597ce425d6d","execution":{"iopub.status.busy":"2024-09-05T09:10:40.782728Z","iopub.execute_input":"2024-09-05T09:10:40.783150Z","iopub.status.idle":"2024-09-05T09:10:41.288445Z","shell.execute_reply.started":"2024-09-05T09:10:40.783112Z","shell.execute_reply":"2024-09-05T09:10:41.287654Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"<|begin_of_text|>###\nYou are an AI assistant trained to assess the semantic similarity between two paragraphs. Given two paragraphs, analyze their meaning and provide a similarity score between 0 and 1 based purely on a cosine similarity function.\n###\nParagraph 1: North Korea Delegation Meets With South Korean Officials\n###\nParagraph 2: South Korea declares end to MERS outbreak\n\nProvide your similarity score (a single number between 0 and 1) and no explanation needed.\n\nThe similarity score between the two paragraphs is. [/INST]\n<|eot_id|>\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<a name=\"Save\"></a>\n### Saving, loading finetuned models\nTo save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n\n**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!","metadata":{"id":"uMuVrWbjAzhc"}},{"cell_type":"code","source":"!pip install --upgrade bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-09-01T09:02:47.639814Z","iopub.execute_input":"2024-09-01T09:02:47.640738Z","iopub.status.idle":"2024-09-01T09:03:01.553690Z","shell.execute_reply.started":"2024-09-01T09:02:47.640697Z","shell.execute_reply":"2024-09-01T09:03:01.552482Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.43.3)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"# model.save_pretrained(\"lora_model\") # Local saving\n# tokenizer.save_pretrained(\"lora_model\")\nmodel.push_to_hub(\"lolnicetry/lora_model\", token = \"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\") # Online saving\ntokenizer.push_to_hub(\"lolnicetry/lora_model\", token = \"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\") # Online saving","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":130,"referenced_widgets":["56db586213ff41b8ad24b0dccf45d784","6c16b750eb6446c786ca161824242b25","c848086dbd304393bef04cb35bbe71a1","2e6c1e4873fd411a843f7d9be9f23554","f96511ae28354340bc985fec6f4c1352","937e369bd97c463487d25b3a795a987f","a2610909c0294073a21aee3c7f578381","0b227a8babca4ba09c8d37ebaa8d31da","6ecfc25bebd845909b481cf404f556c7","45afc85954454ec191ac5e7ac0561b16","166797f31534422a9ba04481d6656561","0bdde16038674f1585b00d92785893d0","f6e2e25496724ddda2f1d09188480f20","75d5b9da3a8c4fa9a92f150a7110f77a","fcb98ce31da24386b93d3aebbde82b32","920d2dd713514b12b9c139e3520f2a6c","516baa04d6c649178fabc54915cc7dd2","5337ecad36d14ec59ebaf637b4e63759","7edc4e0a623b4264b89e04d4f8175f0d","a82c4c30a05f4ba6894466fcb70e0815","e2da198438294b7e82f2bf8fe37faa31","ad23989074434310b42411ec657591b6","e03ed95c09d64d27b044695dd28bb39a","d2bed13ef1bf48d7be1adda75872ba60","e96b6eabfe4c4c778d60bf6128e3f32d","69584268c9ab4780865d451e26a7794a","e6d0b86bc4974ff9a27b4890dc026ddb","669eac91787e4a32885d4d87239e8929","499bf4b92f44410ebe52a117467dd10c","04da4cead6114d53a923fc6bc13f5698","ac97efe66be9461b826cd7479361c349","75c188864be749e6875bc4aad51c2f69","183582df6dae4b3e8fa0749f87ff1f7a"]},"id":"upcOlWe7A1vc","outputId":"c5059a25-2017-4970-fbe8-e8d5b19092dc","execution":{"iopub.status.busy":"2024-09-01T09:03:55.607208Z","iopub.execute_input":"2024-09-01T09:03:55.607645Z","iopub.status.idle":"2024-09-01T09:03:58.455892Z","shell.execute_reply.started":"2024-09-01T09:03:55.607603Z","shell.execute_reply":"2024-09-01T09:03:58.453853Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"},{"name":"stdout","text":"Saved model to https://huggingface.co/lolnicetry/lora_model\n","output_type":"stream"},{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:","metadata":{"id":"AEEcJ4qfC7Lp"}},{"cell_type":"code","source":"if False:\n    from unsloth import FastLanguageModel\n    model, tokenizer = FastLanguageModel.from_pretrained(\n        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n        max_seq_length = max_seq_length,\n        dtype = dtype,\n        load_in_4bit = load_in_4bit,\n    )\n    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n\n# alpaca_prompt = You MUST copy from above!\n\ninputs = tokenizer(\n[\n    alpaca_prompt.format(\n        \"What is a famous tall tower in Paris?\", # instruction\n        \"\", # input\n        \"\", # output - leave this blank for generation!\n    )\n], return_tensors = \"pt\").to(\"cuda\")\n\nfrom transformers import TextStreamer\ntext_streamer = TextStreamer(tokenizer)\n_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MKX_XKs_BNZR","outputId":"0f368dbf-fee3-4796-d2c1-fa4598b29c13"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n\n\n### Instruction:\n\nWhat is a famous tall tower in Paris?\n\n\n\n### Input:\n\n\n\n\n\n### Response:\n\nOne of the most famous and iconic tall towers in Paris is the Eiffel Tower. Standing at 324 meters (1,063 feet) tall, this wrought iron tower is a symbol of the city and a must-see attraction for tourists from all over the world.<|end_of_text|>\n"}]},{"cell_type":"markdown","source":"You can also use Hugging Face's `AutoModelForPeftCausalLM`. Only use this if you do not have `unsloth` installed. It can be hopelessly slow, since `4bit` model downloading is not supported, and Unsloth's **inference is 2x faster**.","metadata":{"id":"QQMjaNrjsU5_"}},{"cell_type":"code","source":"if False:\n    # I highly do NOT suggest - use Unsloth if possible\n    from peft import AutoPeftModelForCausalLM\n    from transformers import AutoTokenizer\n    model = AutoPeftModelForCausalLM.from_pretrained(\n        \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n        load_in_4bit = load_in_4bit,\n    )\n    tokenizer = AutoTokenizer.from_pretrained(\"lora_model\")","metadata":{"id":"yFfaXG0WsQuE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Saving to float16 for VLLM\n\nWe also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens.","metadata":{"id":"f422JgM9sdVT"}},{"cell_type":"code","source":"# Merge to 16bit\nif False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\nif False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n\n# Merge to 4bit\nif False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\nif False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n\n# Just LoRA adapters\nif False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\nif False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")","metadata":{"id":"iHjt_SMYsd3P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### GGUF / llama.cpp Conversion\nTo save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n\nSome supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K.\n\n[**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)","metadata":{"id":"TCv4vXHd61i7"}},{"cell_type":"code","source":"# Save to 8bit Q8_0\nif False: model.save_pretrained_gguf(\"model\", tokenizer,)\n# Remember to go to https://huggingface.co/settings/tokens for a token!\n# And change hf to your username!\nif False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n\n# Save to 16bit GGUF\nif False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\nif False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n\n# Save to q4_k_m GGUF\nif False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\nif False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n\n# Save to multiple GGUF options - much faster if you want multiple!\nif False:\n    model.push_to_hub_gguf(\n        \"hf/model\", # Change hf to your username!\n        tokenizer,\n        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n        token = \"\", # Get a token at https://huggingface.co/settings/tokens\n    )","metadata":{"id":"FqfebeAdT073"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in `llama.cpp` or a UI based system like `GPT4All`. You can install GPT4All by going [here](https://gpt4all.io/index.html).\n\n**[NEW] Try 2x faster inference in a free Colab for Llama-3.1 8b Instruct [here](https://colab.research.google.com/drive/1T-YBVfnphoVc8E2E854qF3jdia2Ll2W2?usp=sharing)**","metadata":{"id":"bDp0zNpwe6U_"}},{"cell_type":"markdown","source":"And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/u54VK8m8tk) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n\nSome other links:\n1. Zephyr DPO 2x faster [free Colab](https://colab.research.google.com/drive/15vttTpzzVXv_tJwEk-hIcQ0S9FcEWvwP?usp=sharing)\n2. Llama 7b 2x faster [free Colab](https://colab.research.google.com/drive/1lBzz5KeZJKXjvivbYvmGarix9Ao6Wxe5?usp=sharing)\n3. TinyLlama 4x faster full Alpaca 52K in 1 hour [free Colab](https://colab.research.google.com/drive/1AZghoNBQaMDgWJpi4RbffGM1h6raLUj9?usp=sharing)\n4. CodeLlama 34b 2x faster [A100 on Colab](https://colab.research.google.com/drive/1y7A0AxE3y8gdj4AVkl2aZX47Xu3P1wJT?usp=sharing)\n5. Mistral 7b [free Kaggle version](https://www.kaggle.com/code/danielhanchen/kaggle-mistral-7b-unsloth-notebook)\n6. We also did a [blog](https://huggingface.co/blog/unsloth-trl) with 🤗 HuggingFace, and we're in the TRL [docs](https://huggingface.co/docs/trl/main/en/sft_trainer#accelerate-fine-tuning-2x-using-unsloth)!\n7. `ChatML` for ShareGPT datasets, [conversational notebook](https://colab.research.google.com/drive/1Aau3lgPzeZKQ-98h69CCu1UJcvIBLmy2?usp=sharing)\n8. Text completions like novel writing [notebook](https://colab.research.google.com/drive/1ef-tab5bhkvWmBOObepl1WgJvfvSzn5Q?usp=sharing)\n9. [**NEW**] We make Phi-3 Medium / Mini **2x faster**! See our [Phi-3 Medium notebook](https://colab.research.google.com/drive/1hhdhBa1j_hsymiW9m-WzxQtgqTH_NHqi?usp=sharing)\n10. [**NEW**] We make Gemma-2 9b / 27b **2x faster**! See our [Gemma-2 9b notebook](https://colab.research.google.com/drive/1vIrqH5uYDQwsJ4-OO3DErvuv4pBgVwk4?usp=sharing)\n11. [**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)\n12. [**NEW**] We make Mistral NeMo 12B 2x faster and fit in under 12GB of VRAM! [Mistral NeMo notebook](https://colab.research.google.com/drive/17d3U-CAIwzmbDRqbZ9NnpHxCkmXB6LZ0?usp=sharing)\n\n<div class=\"align-center\">\n  <a href=\"https://github.com/unslothai/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n  <a href=\"https://discord.gg/u54VK8m8tk\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n  <a href=\"https://ko-fi.com/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Kofi button.png\" width=\"145\"></a></a> Support our work if you can! Thanks!\n</div>","metadata":{"id":"Zt9CHJqO6p30"}}]}